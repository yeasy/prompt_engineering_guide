## 9.4 高级 RAG 架构与前沿趋势

随着 RAG 技术的成熟，简单的"Retrieve-Then-Read"管道已难以满足复杂场景的需求。本节将介绍几种代表当前最前沿水平的高级 RAG 架构（Advanced RAG Architectures）。

### 1. 模块化与自适应 RAG

传统的 RAG 是一条固定的流水线：检索 → 生成。而新一代 RAG 架构将各个环节解耦，并根据问题的难度动态调整策略。

#### Self-RAG：自反思检索增强

由 Akari Asai 等人提出的 Self-RAG 是最具影响力的自适应架构，核心思想是**"按需检索"** 和 **"自我反思"**。

```mermaid
flowchart TB
    Query[\"用户问题\"] --> NeedRetrieval{\"需要检索吗?\"}
    NeedRetrieval -->|\"否（如写诗）\"| DirectGen[\"直接生成\"]
    NeedRetrieval -->|\"是\"| Retrieve[\"检索文档\"]
    
    Retrieve --> ParallelGen[\"并行生成多个候选\"]
    ParallelGen --> Critique[\"自我评估\"]
    
    subgraph CritiqueBox[\"评估维度\"]
        IsREL[\"IsREL: 文档相关性\"]
        IsSUP[\"IsSUP: 回答有据可依\"]
        IsUSE[\"IsUSE: 回答有用性\"]
    end
    
    Critique --> CritiqueBox
    CritiqueBox --> Select[\"选择最高分\"]
    DirectGen --> Output[\"输出回答\"]
    Select --> Output
    
    style Critique fill:#fff3e0
    style Select fill:#c8e6c9
```

*图 9.4-1：Self-RAG 工作流程*

**关键创新点**：
- **按需检索**：模型首先判断是否需要外部知识，避免不必要的检索开销
- **多候选生成**：并行生成多个回答版本，增加命中最优解的概率
- **自我打分**：通过三个维度评估回答质量，实现自动质量控制

#### CRAG：纠错式检索增强

CRAG 的核心在于**检测并纠正检索失败**。

```mermaid
flowchart LR
    Query[\"问题\"] --> Retrieve[\"检索\"]
    Retrieve --> Score{\"相关性评分\"}
    Score -->|\"高于阈值\"| Generate[\"正常生成\"]
    Score -->|\"低于阈值\"| WebSearch[\"触发Web搜索\"]
    WebSearch --> Generate
    Generate --> Output[\"输出\"]
    
    style WebSearch fill:#fff3e0
```

*图 9.4-2：CRAG 纠错流程*

**核心机制**：
- 当检索结果相关性低于阈值时，判定为"知识盲区"
- 自动触发 Web 搜索作为兜底，而不是强行用无关文档回答
- 有效降低了因检索失败导致的幻觉

### 2. GraphRAG：融合知识图谱

向量检索擅长语义相似度，但无法处理复杂的**结构化关系**（如"Alice 的老板的老板是谁？"）。Microsoft 提出的 GraphRAG 将知识图谱（Knowledge Graph）引入 RAG。

-   **Indexing**: 从文档中抽取实体（Entity）和关系（Relation），构建图谱。
-   **Retrieval**:
    -   先在图谱中进行多跳（Multi-hop）查询，找到关联路径。
    -   同时进行向量搜索。
    -   融合两者的结果。
-   **优势**: 在需要全局概览（Global Understanding）和复杂推理的场景下，GraphRAG 显著优于传统 RAG。

### 3. 长上下文 RAG (Long-Context RAG)

随着 Gemini 1.5 (1M+ context) 和 Claude 3 (200K context) 的出现，一种观点认为 "RAG 已死，Long Context 即未来"。

**现状与融合**：
-   **大海捞针 (Needle In A Haystack)**：虽然窗口大了，但模型在超长文中提取细节的能力仍有波动。
-   **经济性**：每次把 100 本书塞进 Context 极其昂贵且慢。
-   **未来架构**：**RAG + Long Context**。RAG 负责粗筛出 Top-50 文档（依然很大），然后利用 Long Context 模型一次性阅读这 50 个文档进行综合，替代传统的 Top-5 切片。

### 4. RAG 评估体系 (RAG Evaluation)

没有评估就在"裸奔"。业界主流的评估框架是 **RAGAS** (Retrieval Augmented Generation Assessment)。

#### 核心指标 (The RAG Triad)

1.  **Context Precision (检索精确度)**
    -   *定义*：检索到的文档中，真正相关的文档排在前面的比例。
    -   *问题*：如果相关文档排在第 10 位，模型可能看不到。

2.  **Context Recall (检索召回率)**
    -   *定义*：知识库中所有能回答该问题的文档，被检索出来的比例。
    -   *问题*：如果漏掉了关键文档，答案就不完整。

3.  **Faithfulness (忠实度)**
    -   *定义*：生成的 Answer 中的每一句话，是否都能从 Context 中找到依据？
    -   *目标*：检测幻觉。

4.  **Answer Relevance (答案相关性)**
    -   *定义*：生成的 Answer 是否直接回答了用户的 Query？
    -   *目标*：防止答非所问。

### 小结

RAG 技术正在经历从"简单管道"向"智能 Agent"的演进。无论是 Self-RAG 的自我反思，还是 GraphRAG 的结构化增强，核心目标都是让 AI 更加 **自主** 地决定何时检索、检索什么以及如何利用检索结果。至此，第九章内容全部结束。

### 延伸阅读

-   [Self-RAG: Learning to Retrieve, Generate, and Critique](https://arxiv.org/abs/2310.11511)
-   [Corrective Retrieval Augmented Generation (CRAG)](https://arxiv.org/abs/2401.15884)
-   [Microsoft GraphRAG](https://microsoft.github.io/graphrag/)
