## 9.2 高级检索策略与上下文组装

在 RAG 系统中，"检索（Retrieval）"的质量决定了最终效果的上限。如果你给 LLM 提供了错误的上下文，再强大的模型也无法生成正确的答案。本节将深入探讨提升检索质量的关键策略。

### 1. 混合检索 (Hybrid Search)

单一的向量搜索（Vector Search）虽然擅长捕捉语义，但在处理精确匹配（如特定的人名、产品型号）时往往表现不佳。混合检索通过结合关键词搜索（Sparse Retrieval）和向量搜索（Dense Retrieval）来弥补这一缺陷。

#### 核心算法：融合策略

如何将两种搜索结果合并？目前业界主流采用 **RRF (Reciprocal Rank Fusion)** 算法。

RRF 的核心思想是：如果不确定哪个对，就相信两个系统都认为靠前的结果。其公式为：

$$
score(d) = \sum_{r \in R} \frac{1}{k + rank(d, r)}
$$

其中 $k$ 是常数（通常取 60）。RRF 不依赖具体的相似度分数，只依赖排名，因此具有很好的鲁棒性。

### 2. 重排序 (Reranking)

这是提升 RAG 效果最立竿见影的手段。

-   **第一阶段（检索）**：使用计算量小的双编码器（Bi-Encoders）快速从百万级文档中召回 Top 100。
-   **第二阶段（重排）**：使用精度的交叉编码器（Cross-Encoders，如 BGE-Reranker, Cohere Rerank）对这 100 个结果进行精细打分，选出 Top 5。

**为什么 Cross-Encoder 更强？**
因为它可以捕捉 Query 和 Document 之间深层的交互特征，如果不计计算成本，它的准确率远高于向量相似度。

### 3. 查询转换 (Query Transformation)

用户的原始提问往往是不完整或含糊的。我们需要在检索前优化 Query。

#### HyDE (Hypothetical Document Embeddings)
-   **原理**：先让 LLM 编造一个"假设性回答"，然后用这个回答去检索。
-   **优势**：解决了 Query 和 Document 语义空间不匹配的问题（Query 是问题，Document 是陈述）。

#### 多查询扩展 (Multi-Query)
-   **原理**：将一个复杂问题拆解为多个子视角。
    *   *User*: "对比一下 LangChain 和 LlamaIndex"
    *   *AI*: 生成两个 Query -> "LangChain 的优缺点", "LlamaIndex 的优缺点"
-   **执行**：并行执行搜索，然后去重合并结果。

### 4. 索引优化策略

#### 父文档检索 (Parent Document Retriever)
-   **问题**：大文档块包含丰富上下文但向量不精确，小文档块向量精确但丢失上下文。
-   **方案**：索引时切分成小块（Child Chunks），检索到小块后，返回其所属的父文档块（Parent Chunk）给 LLM。这种"小块索引，大块返回"的策略兼顾了检索精度和上下文完整性。

### 5. 上下文组装 (Context Construction)

拿到文档后，如何喂给模型也是一门学问。

#### "Lost in the Middle" 现象
研究表明，LLM 往往更容易关注上下文的**开头** 和 **结尾**，而忽略中间的信息。
-   **优化策略**：将相关度（Relevance Score）最高的文档放在 Prompt 的开头或结尾，将相关度较低的放在中间。

#### 长上下文的处理
如果检索回来的内容超过了窗口限制：
-   **Map-Reduce**：先对每个文档块进行摘要，再将摘要汇总。
-   **Refine**：串行地让 LLM 阅读文档并逐步优化答案（速度较慢）。

### 9.2.1 关键参数推荐

针对企业级知识库，以下是一组经过验证的经验参数：

| 参数 | 推荐值 | 说明 |
| :--- | :--- | :--- |
| **Chunk Size** | 512 ~ 1024 tokens | 需要涵盖完整语义段落 |
| **Overlap** | 10% ~ 20% | 防止切分点断开语义 |
| **Retrieval Top-K** | 50 ~ 100 | 召回更多候选集给重排序 |
| **Rerank Top-K** | 5 ~ 10 | 最终喂给 LLM 的数量 |

### 9.2.2 小结

好的检索策略是多层级的漏斗：先通过混合检索宽泛召回，再通过重排序精准过滤，最后通过上下文组装巧妙呈现。在下一节中，我们将探讨如何在 Prompt 层面进一步优化 RAG 的生成效果。

### 9.2.3 延伸阅读

-   [Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172) - 关于上下文位置偏见的必读论文
-   [Cohere Rerank Models](https://cohere.com/rerank) - 商业重排序模型的代表
-   [Precise Zero-Shot Dense Retrieval without Relevance Labels (HyDE)](https://arxiv.org/abs/2212.10496) - HyDE 原始论文
