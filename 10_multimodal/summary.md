# 第十章：多模态提示工程

## 本章小结

本章系统探讨了涉及视觉和听觉内容的多模态大模型（如 GPT-4V, Gemini 1.5 Pro, Claude 3.5 Sonnet）的提示词技术。相比纯文本，多模态提示工程不仅需要传递文字指令，还需要精准引导模型将视觉特征与文本逻辑锚定和对齐。

### 关键概念

- **多模态对齐**：模型将图像像素、音频频谱等非结构化信号与文本语义对应起来的能力。
- **空间与时间锚点**：在提示词中通过坐标、区域描述或时间戳来精确指代媒体材料中的特定部分。
- **视觉幻觉**：由于小物体丢失、文字识别（OCR）偏差或过度联想而导致模型强行"看出"不存在的信息。

### 核心要点

1. **多模态模型的特性与局限**
   - 当前多模态模型依然以"文本优先"，视觉理解实质上是一种"视觉到文本的隐性翻译"。
   - 空间定位（找精确坐标）和密集文本识别（复杂图表OCR）仍然是常见的薄弱环节。

2. **图像分析的提示词策略**
   - **坐标引导**：在图像上画出网格或标记出数字边界框，并在提示词中要求模型返回相应的标记名。
   - **多阶推理**：要求模型遵循 `观察 -> 描述局部特征 -> 联系上下文 -> 得出结论` 的思路（类似多模态 CoT）。
   - **聚焦任务**：通过裁剪不相关的边缘甚至高斯模糊背景，从源头减少噪声干扰。

3. **长视频与音频的前处理策略**
   - 由于底层限制，大多数模型分析长视频是采取"抽帧"的方法。
   - 需要在外部进行关键帧提取、重复帧去冗和音频转文字，再混合输入大模型处理。

4. **防幻觉设计法则**
   - 永远提供"内容不清"作为逃生退路（例如："如果图像分辨率不足以辨认车牌号，直接回答'无法辨认'"）。
   - 不要问带有极强暗示引导的封闭式问题（"图里那只猫是站着的对吧？"），而应使用开放描述："描述图中有没有动物，它在做什么"。

### 实践检查清单

- [ ] 是否尽可能裁剪了图像中不需要大模型关注的无关区域？
- [ ] 若需要提取精确坐标或结构化表格提取，是否结合了传统 OCR 和布局解析工具打辅助？
- [ ] 提示词是否足够开放，没有强行引导模型的视觉判断走向歧途？
- [ ] 是否在多图比较的任务中，对不同的图像进行了明确的编号（Image 1, Image 2）并在指令中精准调用？

### 延伸阅读

#### 10.1 多模态大模型进展
- [GPT-4V(ision) System Card](https://cdn.openai.com/papers/GPTV_System_Card.pdf) - OpenAI 视觉大模型的官方技术报告
- [Gemini 1.5 Pro Technical Report](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf) - Gemini 官方技术报告

#### 10.2 多模态提示词指南
- [Anthropic Vision Guide](https://docs.anthropic.com/en/docs/build-with-claude/vision) - Claude 视觉提示词官方最佳实践
- [OpenAI Vision API](https://platform.openai.com/docs/guides/vision) - OpenAI 图像处理指南

### 下一章预告

随着大语言模型介入越来越多甚至掌握敏感业务逻辑的自动化流，安全性成为绕不开的核心议题。在[第十一章](../11_safety_reliability/README.md)，我们将深入探讨大模型常见的安全漏洞（如提示词注入）及其体系化防御手段。

---

[下一章：安全性与可靠性 →](../11_safety_reliability/README.md)
